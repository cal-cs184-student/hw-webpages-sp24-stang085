<html>
<head>
<title>Homework 1</title>
</head>
<body>

<h1>Homework 1</h1>
<h2>Overview</h2>
<p>This project consists of a few main ideas: Rasterization, Supersampling, Transformations, Using Barycentric Coordinates, and Using Mipmaps. For each part, I will give a brief explanation of what the task achieved.
</p>
<h3>Process</h3>
<p>My approach to each problem was to first make sure I knew the end goal was. I did this by watching lectures and looking at discussion notes. After I understood, I would then go and make sure I knew how each function worked and what it did. This was one of the most time consuming parts for me because there were a lot of functions that I didn’t know how to use and C++ is also a new language for me. After I understood how to use all the functions, I would put in my first draft of code and then go off of that to debug (this was definitely the most time-consuming part of the project). 
</p>
<h3>What does this homework accomplish?</h3>
<p>This project allows you to generate images while improving the viewing quality. Rasterizing triangles and Transformations allow the image to appear, while supersampling, interpolation, and mipmaps allow each individual image to blend more seamlessly into one another, which will usually improve the viewing experience.  
</p>
<h3>What have I learned?
</h3>
<p>Through this Homework, I feel that I have learned a lot about the behind-the-scenes processes of each rendering technique. I have also learned a lot about problem-solving when debugging, and different techniques you can use to figure out what’s wrong with your code. Finally, I feel like I am able to understand how each formula works with barycentric coordinates, line equations, linear interpolation, and finding mipmap levels. This homework has overall given me an in-depth understanding of how image production works and different techniques to make images look better.   
</p>
<br>

<h2>Task 1</h2>
<h3>Overview:</h3>
<p>This first task goes through how to produce simple shapes with triangle rasterization. 
</p>
<h3>Process:</h3>
<p>To rasterize triangles, we are given three points and a color to fill in the triangle. Using this information, we can figure out which pixels to color in using line formulas. 
</p>

<p>
e0 = (pX - x0) * (y1 - y0) - (pY - y0) * (x1 - x0);
</p>
<p>
e1 = (pX - x1) * (y2 - y1) - (pY - y1) * (x2 - x1);
</p>
<p>
e2 = (pX - x2) * (y0 - y2) - (pY - y2) * (x0 - x2);
</p>


<h3>Algorithm:</h3>
<p>
The algorithm I ended up using was one that first found the bounding box of the triangle, then went through each row to check if the pixel was inside the triangle. Since you know that there won’t be any valid points outside the bounding box, by finding it first, you won’t waste time searching the rest of the sample_buffer.
</p>
<p>
Additionally, since the shape we are rasterizing is a triangle, for each row that we are checking the bounds for the pixels, once we finish the row, that means that we do not have to finish checking the rest of the row. To take advantage of this, I added a boolean that kept track if we had ‘entered’ the bounds of the triangle. If we had, and the point that was just checked was invalid, then we know that we are done with that row, and therefore can move to the next row. 
</p>
<p>
While I wasn’t able to check the differences in efficiency because of time constraints, I was able to tell that it didn’t check as many points by using the debugger. 
</p>

<h3>Screenshot of basic/test4.svg:</h3>
  <img src="./task1.png" alt="task1" style="width:800px;">


<br>

<h2>Task 2</h2>

<h3>Overview:</h3>
<p>
This task implements supersampling. This is when the image generator takes more samples within the pixel, and then averages out the color. The purpose of this is to make the lines appear smoother, instead of having jagged edges which appear mostly at corners and diagonal lines. Supersampling can also reduce aliasing (which is when information is lost due to low sampling rates). So instead of having jagged lines or random dots at the edges of triangles, we can have a gradual fade as you go from the center to the point of the triangle. 
</p>

<h3>Changes made from Task 1 and algorithm</h3>

<p>
A few modifications that were done in order to incorporate supersampling were:
</p>
<p>
Modifying the sample_buffer size in order to increase the sampling rate of each pixel. This was done in functions set_sample_rate() and set_framebuffer_target().
</p>
<p>
fill_pixel(): changing it to fill in every supersample in the pixel.
</p>
<p>
rasterize_triangle(): changed to take more samples per pixel.
</p>
<p>
resolve_to_framebuffer(): changed to take the average of each pixel according to the amount of super samples there are.
</p>

<h4>Algorithm Walkthrough:</h4>

<p>
The beginning setup (which is nearly the same as when there was no supersampling) includes finding the bounding box of the triangle which will minimize the amount of pixels that have to be checked. 
</p>
<p>
Next, there are two for loops. In this algorithm, we go by every supersampled row in the y axis, and then by every pixel in the x axis. This allows us to skip sampling inside the pixel if we know that there will not be inside the triangle.
</p>
<p>
If the sample that is checked happens to be a valid point inside the triangle, then there is another for loop that checks the rest of the row
</p>
<p>
What does this mean and how is it faster? For example, if we have a pixel that has a sample_rate of 16, it means that there are 4 total samples in the x direction multiplied by 4 total samples in the y-direction which results in 16 total samples in a single pixel. This algorithm will check every row in the y direction (4) and then only one sample in the x-direction per row. This is a total of 4 samples per pixel.
</p>

<h3>Screenshots of basic/test4.svg:</h3>

<h4>1 sample/pixel:</h4>
  <img src="./task2_1.png" alt="task2" style="width:800px;">

<h4>4 samples/pixel:</h4>
  <img src="./task2_4.png" alt="task2" style="width:800px;">

<h4>16 samples/pixel:</h4>
  <img src="./task2_16.png" alt="task2" style="width:800px;">


<br>





<h2>Task 3</h2>

<h3>Overview:</h3>
<p>
This part mainly implemented transforms such as scaling, rotating, and translating. 
</p>
<h3>Robot_2.0</h3>
<p>
For this cube-person, I changed the pose and outfit in order to make a ballerina. I changed the arm position and rotation to make it more curved and slightly more natural, and added hair and a skirt. Finally, I changed the color of the body parts so that it would look like the ballerina was wearing tights, a leotard, and a tutu.
</p>

  <img src="./task3.png" alt="task3" style="width:800px;">
<br>




<h2>Task 4</h2>
<h3>Overview:</h3>
<p>
This task implemented barycentric coordinates in order to form smooth transitions between pixels given the colors at each of the points. 
</p>
<h3>What are barycentric coordinates?</h3>
<p>
Barycentric coordinates refers to a system that uses the three points of a triangle (A, B, C) in order to define another point (D). However close point D is to the others is reflected in the equation ɑA + βB + ɣC = D, where ɑ, β, and ɣ reflect how close point D is to points A, B and C, respectively. 
</p>
<img src="./task5_triangle.png" alt="task4" style="width:800px;">



<h3>Example:</h3>
<p>
Take a look at this triangle above. ɑ will represent the red (A), β for the blue (B), and ɣ for the green (C). If ɑ = 1, this means that point D = A, if β = 1 then Point D = B, and so on. Intuitively, using the triangle as a guide, the closer point D is to the red corner, the higher ɑ will be. 
</p>
<p>
Since ɑ + β + ɣ = 1, we can use this to figure out how ‘green’, ‘blue’ or ‘red’ point D will be based on the colors defined in the corners. 
</p>

<h4>Screenshot of svg/basic/test7.svg with sample_rate = 1:</h4>
  <img src="./task4_wheel.png" alt="task4" style="width:800px;">

<br>





<h2>Task 5</h2>


<h3>Overview:</h3>
<p>
This task is similar to the other triangle rasterizing tasks except for when we sample the color to produce the pixel, we have to sample it from an image instead of being given a single color, or interpolating it from triangle points. The way we sample in this part is also interesting because the triangles we are extracting the color from may not be the exact same proportions as it is on the image we’re trying to render. This means that we can render stretched or squished versions of the original images we sample from.
</p>
<h3>What is pixel sampling?</h3>
<p>
Pixel sampling means that you use another image to sample the colors in the shapes you’re trying to make instead of using a single color like in task 1, or barycentric averages like in task 4. 
</p>

<h3>How does it work?</h3>
<p>
In the function, you are given a texture (image), three sets of points (mapping to your final, rendered image), and their corresponding uv points (mapping to the image). Using this information, you do similar calculations from task 1 and 4 to find which points are inside the triangle. The only thing that’s different is finding the value for what color it is. To do this, we have to use barycentric coordinates (similar to task 4) in order to find the corresponding coordinates in the texture map. In other words, if we find the ɑ, β, and ɣ values, we will be able to find the relative point on the texture map. Using that point, we can use sample_nearest or sample_bilinear to extrapolate the color and send it to the sample_buffer.
</p>

<h3>What is nearest sampling and bilinear sampling? What’s the difference?</h3>
<p>
To put it simply, bilinear sampling means to take the weighted averages of the 4 nearest color samples (u00, u01, u10, u11), depending on how close the point is to each pixel. This type of sampling uses linear interpolation (lerp) between two points (u00, u10), another lerp between the other two points (u01, u11), and then finally lerps them together. This gives a final color with the equation of lerp(lerp(u00, u10), lerp(u01, u11)). 
</p>
<p>
On the other hand, nearest sampling is much less complicated, and simply requires you to return the color of the nearest pixel. 
</p>
<p>
The difference is that nearest sampling will sometimes cause random spots of color to appear and the pixels are more defined, while bilinear sampling will give you a smoother transition between each color. 
</p>


<h3>Examples:</h3>

<h4> Nearest sampling, 1 sample/pixel:</h4>
  <img src="./task5_near_1.png" alt="task5" style="width:1200px;">

<h4> Nearest sampling, 16 samples/pixel:</h4>
  <img src="./task5_near_16.png" alt="task5" style="width:1200px;">

<h4> Bilinear sampling, 1 sample/pixel:</h4>
  <img src="./task5_bilinear_1.png" alt="task5" style="width:1200px;">

<h4> Bilinear sampling, 16 samples/pixel:</h4>
  <img src="./task5_bilinear_16.png" alt="task5" style="width:1200px;">


<h4>Comments:</h4>
<p>
Taking a look at the zoomed in area, there is a large difference between sample 1 per pixel and supersampling 16 per pixel; and there is another large difference when using bilinear sampling vs. nearest sampling at 1 sample per pixel. On the contrary, there is not much difference between nearest and bilinear sampling when supersampling.  
</p>
<p>
This is because both supersampling and bilinear sampling are both methods that take the average of nearby colors, which will smooth out the transitions between colors and lines. Overall, using only 1 sample per pixel and nearest sampling can cause huge jumps in the image, and using supersampling and bilinear sampling can help to average out the values and create smoother transitions between pixels. 
</p>



<br>






<h2>Task 6</h2>

<h3>Overview:</h3>
<p>
This task is used to implement Level Sampling with mipmaps in order to create smoother transitions when images are squashed or stretched. 
</p>

<h3>What is Level Sampling?</h3>
<p>
Level sampling is when you sample from different versions of the same image. Each version, or mipmap, can be described as having a level assigned to it, and the higher the level, the more blurred the image will be. Depending on how squashed or stretched the image is, you can choose which mipmap to use: A lower level for stretched areas, and a higher level for squished areas. 
</p>

<h3>Implementation:</h3>
<p>
In task 5, we used barycentric coordinates to find corresponding points (uv) from the image to the texture. To calculate the level, we have to first find the difference vectors, which can be calculated by plugging in (x+1, y), and (x, y+1) to find the barycentric coordinates of each. Using those values, we can find the level after scaling the vectors by the image width and height, finding the max value of each normalized vector, and then taking the log of that value. 
</p>

<p>Once we find the level, we can use that to take samples from that mipmap and return it to the frame_buffer.</p>


<h3>Now that we know all of this, what are the tradeoffs of each technique?</h3>

<h4>Supersampling: </h4>
<p>
With supersampling, you can get a very nice and even result, and it can significantly reduce aliasing. However, it takes a lot of memory and time to calculate as you start to take more samples per pixel. This is because you need to be able to store every single sample value you take, which can be very costly. Depending on the amount of samples per pixel, super sampling can be one of the most time and memory consuming methods. 
</p>

<h4>Pixel Sampling: </h4>
<p>Pixel sampling is much faster than the other methods because it does not require nearly the same amount of calculations. It does not have to sample as many pixels, nor does it have to calculate difference vectors. And while nearest pixel sampling can have aliasing, bilinear sampling can reduce that dramatically. Pixel sampling also does not require as much storage as the other methods because it doesn’t require the frame_buffer to be resized, nor does it have to create mipmaps </p>

<h4>Level Sampling: </h4>
<p>Level sampling can reduce aliasing in very cramped areas of the image. However, sometimes the levels that are calculated don’t reflect the amount of blurring that needs to occur, and can therefore lead to more aliasing when it becomes too blurry. However, it is faster than supersampling and does not take up as much memory, however, it is still more memory consuming than pixel sampling because it needs to calculate/store mipmaps and difference vectors.
</p>


<h3>Example:</h3>

<h4>L_0, P_NEAREST:</h4>
  <img src="./L0-p_nearest.png" alt="task6" style="width:800px;">

<h4>L_0, P_LINEAR:</h4>
  <img src="./L0-p_linear.png" alt="task6" style="width:800px;">
  
<h4>L_NEAREST, P_NEAREST:</h4>
  <img src="./l_near-p_near.png" alt="task6" style="width:800px;">
  
<h4>L_NEAREST, P_LINEAR:</h4>
  <img src="./L_nearest-P_linear.png" alt="task6" style="width:800px;">
  
  

<h2>Notes:</h2>
  <p>I'm not going to lie, I had a lot of trouble on this, but I got through it!
    I got to learn a lot about this and the only thing I wished I had done was search for a partner earlier :( 
</p>
  <p> I also think that I wasn't able to implement Level sampling quite right, but I tried a lot of different things and it wouldn't 
    get quite right, but it was good enough. There are a few lines that appear for the edges of the triangles, and it gets 
    really blurry when you zoom out (not sure if that is correct or not).
</p>
    <p> But anyways, here's some fun screenshots I took of some interesting things:
</p>
  <img src="./fun1.png" alt="fun" style="width:800px;">
  <img src="./fun2.png" alt="fun" style="width:800px;">
  <img src="./fun3.png" alt="fun" style="width:800px;">
  <p> Here's also a screenshot of when my Level sampling was working correctly:
</p>
  <img src="./level_1.png" alt="fun" style="width:800px;">
  <img src="./level_2.png" alt="fun" style="width:800px;">

  <p> Thanks for reading!
</p>
  
</body>
</html>


